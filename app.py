# –°–∏—Å—Ç–µ–º–∞ HR —Å AI, –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ workflow - –ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è
import streamlit as st
import os
import json
import sqlite3
import time
import psutil
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict
import subprocess
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np
import shutil
from openai import OpenAI
import faiss
from rank_bm25 import BM25Okapi
from io import BytesIO
import PyPDF2
from docx import Document
import pdfplumber
import openpyxl
import tempfile

# SciBox API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
SCIBOX_CONFIG = {
    'api_key': "sk-LRwqBFBToIkqBPogfcTxlw",
    'base_url': "https://llm.t1v.scibox.tech/v1",
    'llm_model': "Qwen2.5-72B-Instruct-AWQ",
    'embedding_model': "bge-m3"
}

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI –¥–ª—è SciBox
client = OpenAI(
    api_key=SCIBOX_CONFIG['api_key'],
    base_url=SCIBOX_CONFIG['base_url']
)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
SCIBOX_CONFIG['client'] = client

# Streamlit –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
st.set_page_config(
    page_title="AI HR —Å–∏—Å—Ç–µ–º–∞ —Å –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏–µ–π | MilRAG",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ü—É—Ç–∏ –¥–ª—è workflow
JOB_RESUME_DIR = Path("./job_resume")
MANAGER_REVIEW_DIR = Path("./manager_review")
HR_FINAL_DIR = Path("./hr_final")
HR_DATABASE_PATH = "hr_shared_database.db"

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è workflow
for dir_path in [JOB_RESUME_DIR, MANAGER_REVIEW_DIR, HR_FINAL_DIR]:
    dir_path.mkdir(exist_ok=True)
    for subdir in ["pending", "approved", "rejected"]:
        (dir_path / subdir).mkdir(exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state
if 'monitoring_active' not in st.session_state:
    st.session_state.monitoring_active = False

if 'user_profile' not in st.session_state:
    st.session_state.user_profile = None

if 'scan_history' not in st.session_state:
    st.session_state.scan_history = []

if 'scanned_skills' not in st.session_state:
    st.session_state.scanned_skills = {}

if 'skills_edit_mode' not in st.session_state:
    st.session_state.skills_edit_mode = False

if 'current_user_role' not in st.session_state:
    st.session_state.current_user_role = "employee"

@dataclass
class SkillDetection:
    skill_name: str
    evidence_type: str  # "process", "package", "file", "command"
    confidence: float   # 0.0 - 1.0
    last_detected: datetime
    total_time_minutes: int = 0
    frequency: int = 1
    description: str = ""
    category: str = ""
    experience_level: str = "–ù–∞—á–∏–Ω–∞—é—â–∏–π"  # "–ù–∞—á–∏–Ω–∞—é—â–∏–π", "–°—Ä–µ–¥–Ω–∏–π", "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π"
    icon: str = "üîß"

@dataclass
class UserProfile:
    username: str
    session_start: datetime
    skills_detected: Dict[str, SkillDetection]
    total_xp: int = 0
    level: int = 1
    badges: Set[str] = None
    daily_streak: int = 0
    last_activity: datetime = None
    additional_info: str = ""
    contact_info: Dict[str, str] = None
    career_goals: str = ""
    current_projects: List[str] = None

    def __post_init__(self):
        if self.badges is None:
            self.badges = set()
        if self.last_activity is None:
            self.last_activity = datetime.now()
        if self.contact_info is None:
            self.contact_info = {}
        if self.current_projects is None:
            self.current_projects = []


class AICareerConsultant:
    """AI –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –¥–ª—è –∫–∞—Ä—å–µ—Ä–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""

    def __init__(self):
        self.client = OpenAI(
            api_key=SCIBOX_CONFIG['api_key'],
            base_url=SCIBOX_CONFIG['base_url']
        )

    def generate_career_recommendations(self, profile_data: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—å–µ—Ä–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —á–µ—Ä–µ–∑ AI"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è
            profile_info = profile_data.get('profile_info', {})
            skills = profile_data.get('skills', {})
            user_profile = profile_data.get('user_profile', {})

            skills_list = []
            for skill_name, skill_data in skills.items():
                level = skill_data.get('experience_level', '–ù–∞—á–∏–Ω–∞—é—â–∏–π')
                confidence = skill_data.get('confidence', 0)
                skills_list.append(f"{skill_name} ({level}, {confidence:.2f})")

            prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –∏ –¥–∞–π –∫–∞—Ä—å–µ—Ä–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

–ü–†–û–§–ò–õ–¨ –°–û–¢–†–£–î–ù–ò–ö–ê:
–ò–º—è: {profile_info.get('user_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–ñ–µ–ª–∞–µ–º–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å: {profile_info.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–õ–æ–∫–∞—Ü–∏—è: {profile_info.get('location', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–£—Ä–æ–≤–µ–Ω—å: {user_profile.get('level', 1)}
–û–±—â–∏–π XP: {user_profile.get('total_xp', 0)}

–ù–ê–í–´–ö–ò:
{chr(10).join(skills_list[:10])}

–ó–ê–î–ê–ß–ê: 
–î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ä—å–µ—Ä–Ω–æ–º—É —Ä–∞–∑–≤–∏—Ç–∏—é, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏, –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞–≤—ã–∫–∞—Ö.
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º.
"""

            response = self.client.chat.completions.create(
                model=SCIBOX_CONFIG['llm_model'],
                messages=[
                    {"role": "system", "content": "–¢—ã - –æ–ø—ã—Ç–Ω—ã–π HR –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏ –∫–∞—Ä—å–µ—Ä–Ω—ã–π –∫–æ—É—á."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}"


class HRDatabaseManager:
    def __init__(self, db_path: str = HR_DATABASE_PATH):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö HR"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS employees (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL,
                    position TEXT,
                    department TEXT,
                    email TEXT,
                    phone TEXT,
                    skills TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            conn.execute("""
                CREATE TABLE IF NOT EXISTS positions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    description TEXT,
                    requirements TEXT,
                    department TEXT,
                    source_file TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            conn.execute("""
                CREATE TABLE IF NOT EXISTS scanned_profiles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL,
                    skills_detected TEXT,
                    total_xp INTEGER DEFAULT 0,
                    level INTEGER DEFAULT 1,
                    badges TEXT,
                    scan_data TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            conn.commit()

    def get_all_employees(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM employees")
            return [dict(row) for row in cursor.fetchall()]

    def get_all_positions(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM positions")
            return [dict(row) for row in cursor.fetchall()]

    def get_scanned_profiles(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM scanned_profiles")
            profiles = []
            for row in cursor.fetchall():
                profile = dict(row)
                # –ü–∞—Ä—Å–∏–º JSON –ø–æ–ª—è
                try:
                    profile['skills_detected'] = json.loads(profile['skills_detected'] or '{}')
                    profile['badges'] = json.loads(profile['badges'] or '[]')
                    profile['scan_data'] = json.loads(profile['scan_data'] or '{}')
                except:
                    pass
                profiles.append(profile)
            return profiles

    def add_scanned_profile(self, profile_data: Dict) -> int:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                INSERT INTO scanned_profiles (username, skills_detected, total_xp, level, badges, scan_data)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                profile_data.get('username', ''),
                json.dumps(profile_data.get('skills_detected', {}), ensure_ascii=False),
                profile_data.get('total_xp', 0),
                profile_data.get('level', 1),
                json.dumps(profile_data.get('badges', []), ensure_ascii=False),
                json.dumps(profile_data.get('scan_data', {}), ensure_ascii=False)
            ))
            conn.commit()
            return cursor.lastrowid

    def add_position(self, position_data: Dict) -> int:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                INSERT INTO positions (title, description, requirements, department, source_file)
                VALUES (?, ?, ?, ?, ?)
            """, (
                position_data.get('title', ''),
                position_data.get('description', ''),
                position_data.get('requirements', ''),
                position_data.get('department', ''),
                position_data.get('source_file', '')
            ))
            conn.commit()
            return cursor.lastrowid


class HRSystemAdvanced:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è HR —Å–∏—Å—Ç–µ–º–∞ —Å AI –∏ –ø–æ–∏—Å–∫–æ–º"""

    def __init__(self):
        self.db = HRDatabaseManager()
        self.client = OpenAI(
            api_key=SCIBOX_CONFIG['api_key'],
            base_url=SCIBOX_CONFIG['base_url']
        )
        self.faiss_index = None
        self.documents = []
        self.bm25 = None
        self._init_search_indexes()

    def _init_search_indexes(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã
            employees = self.db.get_all_employees()
            positions = self.db.get_all_positions()
            profiles = self.db.get_scanned_profiles()

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            documents = []

            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
            for emp in employees:
                doc_text = f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫: {emp.get('name', '')} {emp.get('position', '')} {emp.get('department', '')} {emp.get('skills', '')}"
                documents.append({
                    'text': doc_text,
                    'metadata': {'type': 'employee', 'data': emp}
                })

            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏–∏
            for pos in positions:
                doc_text = f"–ü–æ–∑–∏—Ü–∏—è: {pos.get('title', '')} {pos.get('description', '')} {pos.get('requirements', '')}"
                documents.append({
                    'text': doc_text,
                    'metadata': {'type': 'position', 'data': pos}
                })

            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–∏–ª–∏
            for profile in profiles:
                skills_text = " ".join([skill for skill in profile.get('skills_detected', {}).keys()])
                doc_text = f"–ü—Ä–æ—Ñ–∏–ª—å: {profile.get('username', '')} –Ω–∞–≤—ã–∫–∏: {skills_text}"
                documents.append({
                    'text': doc_text,
                    'metadata': {'type': 'scanned_profile', 'data': profile}
                })

            self.documents = documents

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25
            if documents:
                corpus = [doc['text'] for doc in documents]
                self.bm25 = BM25Okapi([doc.split() for doc in corpus])

        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞: {e}")

    def parse_document(self, uploaded_file) -> Tuple[str, Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ AI"""
        try:
            content = ""

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            if uploaded_file.type == "application/pdf":
                content = self._extract_pdf_content(uploaded_file)
            elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                content = self._extract_docx_content(uploaded_file)
            elif uploaded_file.type in ["application/vnd.ms-excel", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"]:
                content = self._extract_excel_content(uploaded_file)
            elif uploaded_file.type == "text/csv":
                content = self._extract_csv_content(uploaded_file)
            elif uploaded_file.type == "text/plain":
                content = str(uploaded_file.read(), "utf-8")
            elif uploaded_file.type == "application/json":
                content = str(uploaded_file.read(), "utf-8")

            # AI —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            structured_data = self._structure_with_ai(content, uploaded_file.name)

            return content, structured_data

        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")

    def _extract_pdf_content(self, uploaded_file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file.flush()

                with pdfplumber.open(tmp_file.name) as pdf:
                    content = ""
                    for page in pdf.pages:
                        content += page.extract_text() + "\n"

                os.unlink(tmp_file.name)
                return content
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è PDF: {e}"

    def _extract_docx_content(self, uploaded_file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX"""
        try:
            doc = Document(uploaded_file)
            content = ""
            for paragraph in doc.paragraphs:
                content += paragraph.text + "\n"
            return content
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è DOCX: {e}"

    def _extract_excel_content(self, uploaded_file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel"""
        try:
            df = pd.read_excel(uploaded_file)
            return df.to_string()
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è Excel: {e}"

    def _extract_csv_content(self, uploaded_file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV"""
        try:
            df = pd.read_csv(uploaded_file)
            return df.to_string()
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è CSV: {e}"

    def _structure_with_ai(self, content: str, filename: str) -> Dict:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ AI"""
        try:
            prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

–§–ê–ô–õ: {filename}
–°–û–î–ï–†–ñ–ò–ú–û–ï:
{content[:2000]}

–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏:
1. –ï—Å–ª–∏ —ç—Ç–æ —Ä–µ–∑—é–º–µ - –∏–º—è, –Ω–∞–≤—ã–∫–∏, –æ–ø—ã—Ç, –∫–æ–Ω—Ç–∞–∫—Ç—ã
2. –ï—Å–ª–∏ —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ - –Ω–∞–∑–≤–∞–Ω–∏–µ, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –æ–ø–∏—Å–∞–Ω–∏–µ
3. –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ - –ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–∞–≤—ã–∫–∏, –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å –ø–æ–ª—è–º–∏:
- type: —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (resume/vacancy/employee_profile/other)
- extracted_data: –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- skills: —Å–ø–∏—Å–æ–∫ –Ω–∞–≤—ã–∫–æ–≤
- metadata: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
"""

            response = self.client.chat.completions.create(
                model=SCIBOX_CONFIG['llm_model'],
                messages=[
                    {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É HR –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.1
            )

            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            result = json.loads(response.choices[0].message.content)
            return result

        except Exception as e:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return {
                'type': 'other',
                'extracted_data': {'content': content[:500]},
                'skills': [],
                'metadata': {'filename': filename, 'error': str(e)}
            }

    def add_document_to_database(self, structured_data: Dict, filename: str) -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            doc_type = structured_data.get('type', 'other')

            if doc_type == 'resume' or doc_type == 'scanned_profile':
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –ø—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞
                return self._add_employee_profile(structured_data, filename)
            elif doc_type == 'vacancy':
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –ø–æ–∑–∏—Ü–∏—é
                return self._add_position(structured_data, filename)
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
                return self._add_general_document(structured_data, filename)

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–∞–∑—É: {e}"

    def _add_employee_profile(self, data: Dict, filename: str) -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞"""
        try:
            extracted = data.get('extracted_data', {})

            profile_data = {
                'username': extracted.get('name', data.get('username', 'Unknown')),
                'skills_detected': data.get('skills_detected', {}),
                'total_xp': data.get('total_xp', 0),
                'level': data.get('level', 1),
                'badges': data.get('badges', []),
                'scan_data': data
            }

            profile_id = self.db.add_scanned_profile(profile_data)
            self._update_search_indexes()

            return f"–ü—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω (ID: {profile_id})"

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {e}"

    def _add_position(self, data: Dict, filename: str) -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏"""
        try:
            extracted = data.get('extracted_data', {})

            position_data = {
                'title': extracted.get('title', 'Unknown Position'),
                'description': extracted.get('description', ''),
                'requirements': str(data.get('skills', [])),
                'department': extracted.get('department', ''),
                'source_file': filename
            }

            position_id = self.db.add_position(position_data)
            self._update_search_indexes()

            return f"–ü–æ–∑–∏—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ (ID: {position_id})"

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏: {e}"

    def _add_general_document(self, data: Dict, filename: str) -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        return f"–î–æ–∫—É–º–µ–Ω—Ç {filename} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω"

    def _update_search_indexes(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤"""
        self._init_search_indexes()

    def hybrid_search(self, query: str, k: int = 5) -> List[Dict]:
        """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ BM25 + —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π"""
        try:
            if not self.bm25 or not self.documents:
                return []

            # BM25 –ø–æ–∏—Å–∫
            query_tokens = query.split()
            bm25_scores = self.bm25.get_scores(query_tokens)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for i, (doc, score) in enumerate(zip(self.documents, bm25_scores)):
                if score > 0:
                    results.append({
                        'text': doc['text'],
                        'metadata': doc['metadata'],
                        'score': float(score)
                    })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            results.sort(key=lambda x: x['score'], reverse=True)

            return results[:k]

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []

    def smart_query_with_context(self, query: str, k: int = 5) -> str:
        """–£–º–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ RAG"""
        try:
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            search_results = self.hybrid_search(query, k)

            if not search_results:
                return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –∑–∞–ø—Ä–æ—Å."

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_parts = []
            for result in search_results:
                context_parts.append(f"[{result['metadata']['type']}] {result['text']}")

            context = "\n\n".join(context_parts)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            prompt = f"""
–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ HR –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ. 
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º.
–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∏ –ø—Ä–∏–≤–µ–¥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
"""

            response = self.client.chat.completions.create(
                model=SCIBOX_CONFIG['llm_model'],
                messages=[
                    {"role": "system", "content": "–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å HR –¥–∞–Ω–Ω—ã–º–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.1
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}"


class SmartAutoProfiler:
    """Smart Auto-Profiler —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –Ω–∞–≤—ã–∫–æ–≤"""

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    PROCESS_SKILLS = {
        "pycharm": {"skill": "Python Development", "confidence": 0.95, "category": "Development", "icon": "üêç"},
        "pycharm64": {"skill": "Python Development", "confidence": 0.95, "category": "Development", "icon": "üêç"},
        "code": {"skill": "Code Editing", "confidence": 0.8, "category": "Development", "icon": "üíª"},
        "docker": {"skill": "DevOps & Containerization", "confidence": 0.9, "category": "DevOps", "icon": "üê≥"},
        "docker-compose": {"skill": "Container Orchestration", "confidence": 0.9, "category": "DevOps", "icon": "üêô"},
        "jupyter": {"skill": "Data Science & Jupyter", "confidence": 0.9, "category": "Data Science", "icon": "üìä"},
        "jupyter-lab": {"skill": "Advanced Data Science", "confidence": 0.95, "category": "Data Science", "icon": "üî¨"},
        "mysql": {"skill": "MySQL Database", "confidence": 0.85, "category": "Database", "icon": "üóÑÔ∏è"},
        "postgres": {"skill": "PostgreSQL Database", "confidence": 0.85, "category": "Database", "icon": "üêò"},
        "git": {"skill": "Version Control", "confidence": 0.9, "category": "Development", "icon": "üåø"},
        "node": {"skill": "Node.js Development", "confidence": 0.8, "category": "Development", "icon": "üü¢"},
        "npm": {"skill": "Package Management", "confidence": 0.7, "category": "Development", "icon": "üì¶"},
        "python": {"skill": "Python Programming", "confidence": 0.85, "category": "Development", "icon": "üêç"},
        "tensorflow": {"skill": "Deep Learning", "confidence": 0.95, "category": "AI/ML", "icon": "üß†"},
        "streamlit": {"skill": "Web App Development", "confidence": 0.9, "category": "Development", "icon": "‚ö°"},
        "fastapi": {"skill": "API Development", "confidence": 0.9, "category": "Development", "icon": "üöÄ"},
        "nginx": {"skill": "Web Server Administration", "confidence": 0.8, "category": "DevOps", "icon": "üåê"},
        "ansible": {"skill": "Configuration Management", "confidence": 0.9, "category": "DevOps", "icon": "‚öôÔ∏è"},
        "kubectl": {"skill": "Kubernetes", "confidence": 0.9, "category": "DevOps", "icon": "‚ò∏Ô∏è"},
        "terraform": {"skill": "Infrastructure as Code", "confidence": 0.9, "category": "DevOps", "icon": "üèóÔ∏è"}
    }

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤
    PACKAGE_SKILLS = {
        "streamlit": {"skill": "Streamlit Web Apps", "confidence": 0.9, "category": "Development", "icon": "‚ö°"},
        "fastapi": {"skill": "FastAPI Development", "confidence": 0.9, "category": "Development", "icon": "üöÄ"},
        "django": {"skill": "Django Web Framework", "confidence": 0.9, "category": "Development", "icon": "üå±"},
        "flask": {"skill": "Flask Microframework", "confidence": 0.8, "category": "Development", "icon": "üå™Ô∏è"},
        "pandas": {"skill": "Data Analysis with Pandas", "confidence": 0.9, "category": "Data Science", "icon": "üêº"},
        "numpy": {"skill": "Scientific Computing", "confidence": 0.8, "category": "Data Science", "icon": "üî¢"},
        "tensorflow": {"skill": "TensorFlow Deep Learning", "confidence": 0.95, "category": "AI/ML", "icon": "üß†"},
        "pytorch": {"skill": "PyTorch Deep Learning", "confidence": 0.95, "category": "AI/ML", "icon": "üî•"},
        "scikit-learn": {"skill": "Machine Learning", "confidence": 0.9, "category": "AI/ML", "icon": "ü§ñ"},
        "opencv": {"skill": "Computer Vision", "confidence": 0.9, "category": "AI/ML", "icon": "üëÅÔ∏è"},
        "selenium": {"skill": "Web Automation", "confidence": 0.8, "category": "Testing", "icon": "ü§ñ"},
        "requests": {"skill": "HTTP Requests & APIs", "confidence": 0.7, "category": "Development", "icon": "üåê"},
        "beautifulsoup4": {"skill": "Web Scraping", "confidence": 0.8, "category": "Development", "icon": "üï∑Ô∏è"},
        "chromadb": {"skill": "Vector Database", "confidence": 0.9, "category": "AI/ML", "icon": "üîç"},
        "langchain": {"skill": "LLM Development", "confidence": 0.9, "category": "AI/ML", "icon": "üîó"},
        "transformers": {"skill": "NLP & Transformers", "confidence": 0.9, "category": "AI/ML", "icon": "ü§ó"},
        "openai": {"skill": "OpenAI API Integration", "confidence": 0.8, "category": "AI/ML", "icon": "üß†"},
        "plotly": {"skill": "Data Visualization", "confidence": 0.8, "category": "Data Science", "icon": "üìä"},
        "matplotlib": {"skill": "Plotting & Visualization", "confidence": 0.8, "category": "Data Science", "icon": "üìà"},
        "seaborn": {"skill": "Statistical Visualization", "confidence": 0.8, "category": "Data Science", "icon": "üìâ"},
        "jupyter": {"skill": "Jupyter Notebooks", "confidence": 0.8, "category": "Data Science", "icon": "üìî"},
        "pytest": {"skill": "Python Testing", "confidence": 0.8, "category": "Testing", "icon": "üß™"},
        "redis": {"skill": "Redis Caching", "confidence": 0.8, "category": "Database", "icon": "üî¥"},
        "celery": {"skill": "Task Queue Processing", "confidence": 0.8, "category": "Development", "icon": "üåø"}
    }

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    FILE_PATTERNS = {
        ".py": {"skill": "Python Development", "confidence": 0.7, "category": "Development", "icon": "üêç"},
        ".js": {"skill": "JavaScript Development", "confidence": 0.7, "category": "Development", "icon": "üìú"},
        ".java": {"skill": "Java Development", "confidence": 0.7, "category": "Development", "icon": "‚òï"},
        ".sql": {"skill": "Database Development", "confidence": 0.8, "category": "Database", "icon": "üóÑÔ∏è"},
        ".dockerfile": {"skill": "Docker Containerization", "confidence": 0.8, "category": "DevOps", "icon": "üê≥"},
        "docker-compose.yml": {"skill": "Docker Compose", "confidence": 0.9, "category": "DevOps", "icon": "üêô"},
        ".tf": {"skill": "Terraform IaC", "confidence": 0.9, "category": "DevOps", "icon": "üèóÔ∏è"},
        ".yaml": {"skill": "YAML Configuration", "confidence": 0.6, "category": "DevOps", "icon": "‚öôÔ∏è"},
        ".yml": {"skill": "YAML Configuration", "confidence": 0.6, "category": "DevOps", "icon": "‚öôÔ∏è"},
        "requirements.txt": {"skill": "Python Dependency Management", "confidence": 0.7, "category": "Development", "icon": "üìã"},
        "package.json": {"skill": "Node.js Development", "confidence": 0.8, "category": "Development", "icon": "üì¶"},
        ".ipynb": {"skill": "Jupyter Notebook Development", "confidence": 0.8, "category": "Data Science", "icon": "üìì"}
    }

    # XP –Ω–∞–≥—Ä–∞–¥—ã
    XP_REWARDS = {
        "new_skill_detected": 100,
        "skill_usage_hour": 15,
        "package_installation": 30,
        "project_creation": 150,
        "daily_coding_streak": 50,
        "weekly_consistency": 200,
        "badge_earned": 300,
        "level_up": 500
    }

    # –°–∏—Å—Ç–µ–º–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
    BADGES = {
        "FirstSteps": {
            "requirement": lambda p: len(p.skills_detected) >= 1,
            "icon": "üéØ",
            "desc": "–ü–µ—Ä–≤—ã–µ —à–∞–≥–∏"
        },
        "SkillCollector": {
            "requirement": lambda p: len(p.skills_detected) >= 5,
            "icon": "üéí",
            "desc": "–°–æ–±—Ä–∞–ª 5 –Ω–∞–≤—ã–∫–æ–≤"
        },
        "Polyglot": {
            "requirement": lambda p: len(p.skills_detected) >= 10,
            "icon": "üåç",
            "desc": "–û—Å–≤–æ–∏–ª 10 –Ω–∞–≤—ã–∫–æ–≤"
        },
        "Expert": {
            "requirement": lambda p: len(p.skills_detected) >= 15,
            "icon": "üë®‚Äçüî¨",
            "desc": "–≠–∫—Å–ø–µ—Ä—Ç - 15 –Ω–∞–≤—ã–∫–æ–≤"
        },
        "PythonMaster": {
            "requirement": lambda p: any("Python" in s.skill_name for s in p.skills_detected.values()),
            "icon": "üêç",
            "desc": "–ú–∞—Å—Ç–µ—Ä Python"
        },
        "MLEnthusiast": {
            "requirement": lambda p: sum(1 for s in p.skills_detected.values() if "ML" in s.skill_name or "Machine Learning" in s.skill_name) >= 2,
            "icon": "ü§ñ",
            "desc": "–≠–Ω—Ç—É–∑–∏–∞—Å—Ç ML"
        },
        "DevOpsEngineer": {
            "requirement": lambda p: sum(1 for s in p.skills_detected.values() if "DevOps" in s.skill_name or "Docker" in s.skill_name) >= 3,
            "icon": "‚öôÔ∏è",
            "desc": "DevOps –∏–Ω–∂–µ–Ω–µ—Ä"
        },
        "DataScientist": {
            "requirement": lambda p: sum(1 for s in p.skills_detected.values() if "Data" in s.skill_name) >= 3,
            "icon": "üìä",
            "desc": "Data Scientist"
        },
        "CodeWarrior": {
            "requirement": lambda p: p.total_xp >= 1000,
            "icon": "‚öîÔ∏è",
            "desc": "–í–æ–∏–Ω –∫–æ–¥–∞ - 1000 XP"
        },
        "DedicationMaster": {
            "requirement": lambda p: p.daily_streak >= 7,
            "icon": "üî•",
            "desc": "–ú–∞—Å—Ç–µ—Ä —É–ø–æ—Ä—Å—Ç–≤–∞ - 7 –¥–Ω–µ–π"
        },
        "Level5Hero": {
            "requirement": lambda p: p.level >= 5,
            "icon": "üèÜ",
            "desc": "–ì–µ—Ä–æ–π 5-–≥–æ —É—Ä–æ–≤–Ω—è"
        },
        "AIPioneer": {
            "requirement": lambda p: any("AI" in s.skill_name or "LLM" in s.skill_name or "OpenAI" in s.skill_name for s in p.skills_detected.values()),
            "icon": "üöÄ",
            "desc": "–ü–∏–æ–Ω–µ—Ä –ò–ò"
        }
    }

    def __init__(self):
        self.profile = st.session_state.get('user_profile')

    def scan_active_processes(self) -> List[SkillDetection]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
        detected_skills = []

        try:
            for proc in psutil.process_iter(['pid', 'name', 'create_time', 'cmdline']):
                try:
                    proc_name = proc.info['name'].lower()
                    cmdline = " ".join(proc.info.get('cmdline', [])).lower()

                    # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
                    for pattern, skill_info in self.PROCESS_SKILLS.items():
                        if pattern in proc_name or pattern in cmdline:
                            create_time = datetime.fromtimestamp(proc.info['create_time'])
                            runtime_minutes = max(1, int((datetime.now() - create_time).total_seconds() / 60))

                            skill = SkillDetection(
                                skill_name=skill_info['skill'],
                                evidence_type='process',
                                confidence=skill_info['confidence'],
                                last_detected=datetime.now(),
                                total_time_minutes=runtime_minutes,
                                category=skill_info['category'],
                                icon=skill_info['icon']
                            )
                            detected_skills.append(skill)
                            break

                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {e}")

        return detected_skills

    def scan_installed_packages(self, venv_path: str) -> List[SkillDetection]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤"""
        detected_skills = []

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏
            possible_paths = [
                Path(venv_path) / "lib" / "python3.11" / "site-packages",
                Path(venv_path) / "lib" / "python3.10" / "site-packages",
                Path(venv_path) / "lib" / "python3.9" / "site-packages",
                Path(venv_path) / "site-packages"
            ]

            site_packages_path = None
            for path in possible_paths:
                if path.exists():
                    site_packages_path = path
                    break

            if site_packages_path and site_packages_path.exists():
                for item in site_packages_path.iterdir():
                    if item.is_dir():
                        package_name = item.name.lower().split('-')[0].replace('_', '-')

                        if package_name in self.PACKAGE_SKILLS:
                            skill_info = self.PACKAGE_SKILLS[package_name]
                            skill = SkillDetection(
                                skill_name=skill_info['skill'],
                                evidence_type='package',
                                confidence=skill_info['confidence'],
                                last_detected=datetime.now(),
                                category=skill_info['category'],
                                icon=skill_info['icon']
                            )
                            detected_skills.append(skill)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ pip list
            try:
                pip_result = subprocess.run([f"{venv_path}/bin/pip", "list", "--format=freeze"],
                                          capture_output=True, text=True, timeout=10)
                if pip_result.returncode == 0:
                    for line in pip_result.stdout.split('\n'):
                        if '==' in line:
                            package_name = line.split('==')[0].lower()
                            if package_name in self.PACKAGE_SKILLS:
                                skill_info = self.PACKAGE_SKILLS[package_name]
                                skill = SkillDetection(
                                    skill_name=skill_info['skill'],
                                    evidence_type='package',
                                    confidence=skill_info['confidence'],
                                    last_detected=datetime.now(),
                                    category=skill_info['category'],
                                    icon=skill_info['icon']
                                )
                                detected_skills.append(skill)
            except:
                pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ pip

        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤: {e}")

        return detected_skills

    def scan_project_files(self, project_dirs: List[str]) -> List[SkillDetection]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤"""
        detected_skills = []
        file_counts = defaultdict(int)

        try:
            for project_dir in project_dirs:
                project_path = Path(project_dir)
                if project_path.exists():
                    # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
                    for file_path in project_path.rglob("*"):
                        if file_path.is_file():
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
                            suffix = file_path.suffix.lower()
                            if suffix in self.FILE_PATTERNS:
                                file_counts[suffix] += 1

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
                            file_name = file_path.name.lower()
                            for pattern, skill_info in self.FILE_PATTERNS.items():
                                if pattern in file_name:
                                    file_counts[pattern] += 1

            # –°–æ–∑–¥–∞–µ–º –Ω–∞–≤—ã–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            for pattern, count in file_counts.items():
                if pattern in self.FILE_PATTERNS and count > 0:
                    skill_info = self.FILE_PATTERNS[pattern]
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º confidence –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
                    confidence = min(0.95, skill_info['confidence'] + (count * 0.05))

                    skill = SkillDetection(
                        skill_name=skill_info['skill'],
                        evidence_type='file',
                        confidence=confidence,
                        last_detected=datetime.now(),
                        frequency=count,
                        category=skill_info['category'],
                        icon=skill_info['icon'],
                        description=f"–ù–∞–π–¥–µ–Ω–æ {count} —Ñ–∞–π–ª–æ–≤ —Ç–∏–ø–∞ {pattern}"
                    )
                    detected_skills.append(skill)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")

        return detected_skills

    def update_profile_xp(self, skills: List[SkillDetection]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ XP –ø—Ä–æ—Ñ–∏–ª—è"""
        if not self.profile:
            return

        # –°—á–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏
        new_skills = []
        for skill in skills:
            if skill.skill_name not in self.profile.skills_detected:
                new_skills.append(skill)
                self.profile.skills_detected[skill.skill_name] = skill

        # –ù–∞—á–∏—Å–ª—è–µ–º XP –∑–∞ –Ω–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏
        xp_gained = 0
        for skill in new_skills:
            xp_gained += self.XP_REWARDS["new_skill_detected"]

        # –ù–∞—á–∏—Å–ª—è–µ–º XP –∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        for skill in skills:
            if skill.evidence_type == 'process' and skill.total_time_minutes > 30:
                hours = skill.total_time_minutes // 60
                xp_gained += hours * self.XP_REWARDS["skill_usage_hour"]

        self.profile.total_xp += xp_gained

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–≤—ã—à–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è
        old_level = self.profile.level
        self.profile.level = (self.profile.total_xp // 200) + 1

        if self.profile.level > old_level:
            xp_gained += self.XP_REWARDS["level_up"]
            self.profile.total_xp += self.XP_REWARDS["level_up"]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
        self.check_new_badges()

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        self.profile.last_activity = datetime.now()

        return xp_gained, new_skills

    def check_new_badges(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π"""
        if not self.profile:
            return

        new_badges = []
        for badge_name, badge_info in self.BADGES.items():
            if badge_name not in self.profile.badges:
                if badge_info["requirement"](self.profile):
                    self.profile.badges.add(badge_name)
                    new_badges.append(badge_name)
                    self.profile.total_xp += self.XP_REWARDS["badge_earned"]

        return new_badges

    def save_profile_to_resume_folder(self, profile_data: Dict, skills_data: Dict) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –≤ –ø–∞–ø–∫—É —Ä–µ–∑—é–º–µ –¥–ª—è —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"profile_{profile_data.get('username', 'user').replace(' ', '_')}_{timestamp}.json"
            filepath = JOB_RESUME_DIR / filename

            # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            export_data = {
                "profile_info": profile_data,
                "skills": {
                    skill_name: {
                        "skill_name": skill.skill_name,
                        "category": skill.category,
                        "experience_level": skill.experience_level,
                        "description": skill.description,
                        "confidence": skill.confidence,
                        "frequency": skill.frequency,
                        "evidence_type": skill.evidence_type,
                        "icon": getattr(skill, 'icon', 'üîß'),
                        "last_detected": skill.last_detected.isoformat()
                    }
                    for skill_name, skill in skills_data.items()
                },
                "user_profile": {
                    "total_xp": self.profile.total_xp,
                    "level": self.profile.level,
                    "badges": list(self.profile.badges) if self.profile.badges else [],
                    "daily_streak": self.profile.daily_streak,
                    "career_goals": getattr(self.profile, 'career_goals', ''),
                    "current_projects": getattr(self.profile, 'current_projects', [])
                },
                "export_timestamp": datetime.now().isoformat(),
                "status": "ready_for_manager_review",
                "workflow_stage": "employee_submitted"
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            return str(filepath)

        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {e}")


def render_header():
    """–†–µ–Ω–¥–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 30px; border-radius: 15px; margin-bottom: 30px;">
        <h1 style="color: white; text-align: center; margin: 0; font-size: 2.5rem;">
            üöÄ AI HR —Å–∏—Å—Ç–µ–º–∞ —Å –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
        </h1>
        <h3 style="color: white; text-align: center; margin: 10px 0 0 0; font-weight: 300;">
            AI –¥–ª—è —Ä–æ—Å—Ç–∞, –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏ –æ—Ç MilRAG
        </h3>
    </div>
    """, unsafe_allow_html=True)


def render_role_selector():
    """–°–µ–ª–µ–∫—Ç–æ—Ä —Ä–æ–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    st.sidebar.markdown("### üë§ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å")

    role = st.sidebar.selectbox(
        "–†–æ–ª—å:",
        ["employee", "manager", "hr"],
        format_func=lambda x: {"employee": "üë®‚Äçüíª –°–æ—Ç—Ä—É–¥–Ω–∏–∫",
                              "manager": "üëî –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å",
                              "hr": "üè¢ HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç"}[x],
        key="role_selector"
    )

    if role != st.session_state.current_user_role:
        st.session_state.current_user_role = role
        st.rerun()

    return role


def render_sidebar():
    """–†–µ–Ω–¥–µ—Ä –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏"""
    st.sidebar.markdown("### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    username = st.sidebar.text_input("üë§ –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:", "")

    venv_path = st.sidebar.text_input("üêç –ü—É—Ç—å –∫ venv:", "/home/karfel/GitHub/venv",
                                    help="–ü—É—Ç—å –∫ Python –æ–∫—Ä—É–∂–µ–Ω–∏—é")

    project_paths_text = st.sidebar.text_area("üìÅ –ü—É—Ç–∏ –∫ –ø—Ä–æ–µ–∫—Ç–∞–º:",
                                            "/home/karfel/GitHub/AI Challenge Sber\n/home/karfel/GitHub/1AX5X5",
                                            help="–ü—É—Ç–∏ –∫ –ø—Ä–æ–µ–∫—Ç–∞–º (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)")

    project_paths = [path.strip() for path in project_paths_text.split('\n') if path.strip()]

    return {
        "username": username,
        "venv_path": venv_path,
        "project_paths": project_paths
    }


def render_gamification_dashboard():
    """–î–∞—à–±–æ—Ä–¥ –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    if not st.session_state.user_profile:
        return

    profile = st.session_state.user_profile

    st.markdown("### üéÆ –ò–≥—Ä–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("–£—Ä–æ–≤–µ–Ω—å", profile.level)
    with col2:
        st.metric("–û–±—â–∏–π XP", profile.total_xp)
    with col3:
        st.metric("–ù–∞–≤—ã–∫–∏", len(profile.skills_detected))
    with col4:
        st.metric("–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è", len(profile.badges))

    # –ü—Ä–æ–≥—Ä–µ—Å—Å –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
    current_level_xp = (profile.level - 1) * 200
    next_level_xp = profile.level * 200
    progress = min(100, ((profile.total_xp - current_level_xp) / (next_level_xp - current_level_xp)) * 100)

    st.markdown(f"**–ü—Ä–æ–≥—Ä–µ—Å—Å –¥–æ —É—Ä–æ–≤–Ω—è {profile.level + 1}:**")
    st.progress(progress / 100)
    st.caption(f"{profile.total_xp - current_level_xp}/{next_level_xp - current_level_xp} XP")

    # –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è
    if profile.badges:
        st.markdown("### üèÜ –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è")
        badge_cols = st.columns(min(len(profile.badges), 6))

        profiler = SmartAutoProfiler()
        for i, badge_name in enumerate(list(profile.badges)[:6]):
            with badge_cols[i]:
                badge_info = profiler.BADGES.get(badge_name, {"icon": "üèÜ", "desc": badge_name})
                st.markdown(f"""
                <div style="text-align: center; padding: 10px; border-radius: 10px; 
                           background: linear-gradient(45deg, #f3ec78, #af4261);">
                    <div style="font-size: 2em">{badge_info['icon']}</div>
                    <div style="font-size: 0.8em; color: white; font-weight: bold">{badge_info['desc']}</div>
                </div>
                """, unsafe_allow_html=True)


def render_skills_editor():
    """–†–µ–¥–∞–∫—Ç–æ—Ä –Ω–∞–≤—ã–∫–æ–≤"""
    if not st.session_state.get('skills_edit_mode', False):
        return False

    st.markdown("### ‚úèÔ∏è –†–µ–¥–∞–∫—Ç–æ—Ä –Ω–∞–≤—ã–∫–æ–≤")
    st.markdown("*–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤*")

    skills = st.session_state.scanned_skills.copy()

    if not skills:
        st.warning("üì≠ –ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ.")
        return False

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–∞–≤—ã–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    skills_by_category = defaultdict(list)
    for skill_name, skill_data in skills.items():
        skills_by_category[skill_data.category].append((skill_name, skill_data))

    edited_skills = {}

    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    categories = list(skills_by_category.keys())
    if categories:
        tabs = st.tabs([f"{skill_data.icon if hasattr(skill_data, 'icon') else 'üìÇ'} {cat}" for cat in categories])

        for i, category in enumerate(categories):
            with tabs[i]:
                st.markdown(f"#### {category}")

                for skill_name, skill_data in skills_by_category[category]:
                    with st.expander(f"{getattr(skill_data, 'icon', 'üîß')} {skill_name}", expanded=True):
                        col1, col2 = st.columns(2)

                        with col1:
                            new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–∞:",
                                                   value=skill_data.skill_name,
                                                   key=f"name_{skill_name}")

                            new_experience = st.selectbox("–£—Ä–æ–≤–µ–Ω—å –æ–ø—ã—Ç–∞:",
                                                        ["–ù–∞—á–∏–Ω–∞—é—â–∏–π", "–°—Ä–µ–¥–Ω–∏–π", "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π"],
                                                        index=["–ù–∞—á–∏–Ω–∞—é—â–∏–π", "–°—Ä–µ–¥–Ω–∏–π", "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π"].index(skill_data.experience_level),
                                                        key=f"exp_{skill_name}")

                            new_category = st.selectbox("–ö–∞—Ç–µ–≥–æ—Ä–∏—è:",
                                                       ["Development", "Data Science", "AI/ML", "DevOps", "Database", "Testing", "–ü—Ä–æ—á–µ–µ"],
                                                       index=["Development", "Data Science", "AI/ML", "DevOps", "Database", "Testing", "–ü—Ä–æ—á–µ–µ"].index(skill_data.category) if skill_data.category in ["Development", "Data Science", "AI/ML", "DevOps", "Database", "Testing", "–ü—Ä–æ—á–µ–µ"] else 6,
                                                       key=f"cat_{skill_name}")

                        with col2:
                            new_description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ:",
                                                         value=skill_data.description,
                                                         key=f"desc_{skill_name}")

                            include_skill = st.checkbox("–í–∫–ª—é—á–∏—Ç—å –≤ –ø—Ä–æ—Ñ–∏–ª—å",
                                                       value=True,
                                                       key=f"include_{skill_name}")

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–≤—ã–∫
                        if include_skill:
                            edited_skill = SkillDetection(
                                skill_name=new_name,
                                evidence_type=skill_data.evidence_type,
                                confidence=skill_data.confidence,
                                last_detected=skill_data.last_detected,
                                total_time_minutes=skill_data.total_time_minutes,
                                frequency=skill_data.frequency,
                                description=new_description,
                                category=new_category,
                                experience_level=new_experience,
                                icon=getattr(skill_data, 'icon', 'üîß')
                            )
                            edited_skills[new_name] = edited_skill

    st.markdown("---")

    # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", type="primary"):
            st.session_state.scanned_skills = edited_skills
            st.session_state.skills_edit_mode = False
            st.success("‚úÖ –ù–∞–≤—ã–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
            st.rerun()

    with col2:
        if st.button("‚ùå –û—Ç–º–µ–Ω–∏—Ç—å"):
            st.session_state.skills_edit_mode = False
            st.rerun()

    with col3:
        if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å"):
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            st.session_state.skills_edit_mode = False
            st.rerun()

    return True


def render_hr_interface():
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ AI –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    st.markdown("## üè¢ HR –ü–∞–Ω–µ–ª—å")
    st.markdown("*–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö*")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã HR
    if 'hr_system' not in st.session_state:
        st.session_state.hr_system = HRSystemAdvanced()

    if 'ai_consultant' not in st.session_state:
        st.session_state.ai_consultant = AICareerConsultant()

    hrsystem = st.session_state.hr_system
    ai_consultant = st.session_state.ai_consultant

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã
    employees = hrsystem.db.get_all_employees()
    positions = hrsystem.db.get_all_positions()
    profiles = hrsystem.db.get_scanned_profiles()

    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±—ã
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ",
        "üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö HR",
        "ü§ñ AI –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç",
        "üìÅ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö",
        "üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞"
    ])

    with tab1:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º —Ä–µ–∑—é–º–µ
        st.markdown("### üìã –†–µ–∑—é–º–µ, –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º")

        # –û–¢–õ–ê–î–ö–ê: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –ø–∞–ø–∫–∏
        st.markdown("#### üîç –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        manager_review_dir = MANAGER_REVIEW_DIR
        st.write(f"**–ë–∞–∑–æ–≤–∞—è –ø–∞–ø–∫–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è:** {manager_review_dir}")
        st.write(f"**–°—É—â–µ—Å—Ç–≤—É–µ—Ç:** {manager_review_dir.exists()}")

        if manager_review_dir.exists():
            subdirs = [d for d in manager_review_dir.iterdir() if d.is_dir()]
            st.write(f"**–ü–æ–¥–ø–∞–ø–∫–∏:** {[d.name for d in subdirs]}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–µ—Ö –ø–æ–¥–ø–∞–ø–æ–∫
            for subdir in subdirs:
                files = list(subdir.glob("*.json"))
                st.write(f"**{subdir.name}:** {len(files)} —Ñ–∞–π–ª–æ–≤")
                if files:
                    for f in files:
                        st.write(f"  - {f.name}")

        st.markdown("---")

        approved_files = []

        # –ò—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        possible_locations = [
            MANAGER_REVIEW_DIR / "approved",
            MANAGER_REVIEW_DIR,  # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ
            JOB_RESUME_DIR  # –ù–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ workflow –ø–æ–ª–æ–º–∞–ª—Å—è
        ]

        for location in possible_locations:
            st.write(f"**–ü—Ä–æ–≤–µ—Ä—è–µ–º:** {location}")
            if location.exists():
                for file_path in location.glob("*.json"):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)

                        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º workflow_stage
                        workflow_stage = data.get('workflow_stage', '')
                        status = data.get('status', '')

                        st.write(f"  - {file_path.name}: stage='{workflow_stage}', status='{status}'")

                        # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ñ–∞–π–ª—ã, –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º
                        if (workflow_stage == 'manager_approved' or
                                status == 'ready_for_hr_review' or
                                'manager_approved' in str(data)):
                            approved_files.append({
                                'filename': file_path.name,
                                'filepath': str(file_path),
                                'data': data,
                                'modified': datetime.fromtimestamp(file_path.stat().st_mtime),
                                'location': str(location)
                            })

                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")

        if not approved_files:
            st.warning("üìÅ –ù–µ—Ç —Ä–µ–∑—é–º–µ, –æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º")
            st.markdown("*–†–µ–∑—é–º–µ –ø–æ—è–≤—è—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –æ–¥–æ–±—Ä–µ–Ω–∏—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º*")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            all_files = []
            for location in possible_locations:
                if location.exists():
                    all_files.extend(list(location.glob("*.json")))

            if all_files:
                st.markdown("#### üîç –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
                for f in all_files:
                    try:
                        with open(f, 'r', encoding='utf-8') as file:
                            data = json.load(file)
                        st.write(
                            f"**{f.name}:** workflow_stage='{data.get('workflow_stage', 'none')}', status='{data.get('status', 'none')}'")
                    except:
                        st.write(f"**{f.name}:** –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è")
        else:
            st.success(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(approved_files)} —Ä–µ–∑—é–º–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –æ–¥–æ–±—Ä–µ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ
            for i, resume_file in enumerate(approved_files):
                data = resume_file['data']
                profile_info = data.get('profile_info', {})
                skills = data.get('skills', {})
                user_profile = data.get('user_profile', {})

                with st.expander(f"üìÑ {profile_info.get('user_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} - {resume_file['filename']}",
                                 expanded=i < 2):
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–∫—É–¥–∞ —Ñ–∞–π–ª
                    st.info(f"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {resume_file['location']}")

                    col1, col2 = st.columns([2, 1])

                    with col1:
                        st.markdown("### üë§ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ")
                        st.write(f"**–ò–º—è:** {profile_info.get('user_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                        st.write(f"**–ñ–µ–ª–∞–µ–º–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å:** {profile_info.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                        st.write(f"**Email:** {profile_info.get('email', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                        st.write(f"**–¢–µ–ª–µ—Ñ–æ–Ω:** {profile_info.get('phone', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                        st.write(f"**–õ–æ–∫–∞—Ü–∏—è:** {profile_info.get('location', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")

                        if data.get('manager_notes'):
                            st.markdown("**–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è:**")
                            st.info(data['manager_notes'])

                        # AI –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
                        if st.button(f"ü§ñ AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è {profile_info.get('user_name', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞')}",
                                     key=f"ai_rec_{i}"):
                            with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏..."):
                                full_profile_data = {
                                    'profile_info': profile_info,
                                    'skills': skills,
                                    'user_profile': user_profile
                                }
                                recommendations = ai_consultant.generate_career_recommendations(full_profile_data)
                                st.markdown("**üéØ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**")
                                st.write(recommendations)

                        # –¢–æ–ø –Ω–∞–≤—ã–∫–∏
                        st.markdown("### üèÜ –¢–æ–ø –Ω–∞–≤—ã–∫–∏")
                        if skills:
                            top_skills = sorted(skills.items(),
                                                key=lambda x: x[1].get('confidence', 0),
                                                reverse=True)[:8]

                            for skill_name, skill_data in top_skills:
                                icon = skill_data.get('icon', 'üîß')
                                level = skill_data.get('experience_level', '–ù–∞—á–∏–Ω–∞—é—â–∏–π')
                                confidence = skill_data.get('confidence', 0)

                                st.write(f"**{icon} {skill_name}** ({level})")
                                st.caption(f"Confidence: {confidence:.2f}")
                        else:
                            st.write("–ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

                    with col2:
                        # –ì–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏—è
                        st.markdown("### üéÆ –ò–≥—Ä–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å")
                        st.metric("–£—Ä–æ–≤–µ–Ω—å", user_profile.get('level', 1))
                        st.metric("–û–±—â–∏–π XP", user_profile.get('total_xp', 0))
                        st.metric("Streak", user_profile.get('daily_streak', 0))

                        badges = user_profile.get('badges', [])[:3]
                        if badges:
                            st.write("**üèÜ –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**")
                            for badge in badges:
                                st.write(f"‚Ä¢ {badge}")

                    # HR —Ñ–æ—Ä–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    st.markdown("---")
                    st.markdown("### üè¢ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ HR")

                    hr_form_key = f"hr_form_{i}"
                    with st.form(hr_form_key):
                        col_a, col_b = st.columns(2)

                        with col_a:
                            department = st.text_input("–û—Ç–¥–µ–ª:",
                                                       value=profile_info.get('department', ''),
                                                       key=f"dept_{i}")
                            salary_range = st.text_input("–ó–∞—Ä–ø–ª–∞—Ç–Ω–∞—è –≤–∏–ª–∫–∞:",
                                                         placeholder="80000-120000",
                                                         key=f"salary_{i}")

                        with col_b:
                            career_track = st.selectbox("–ö–∞—Ä—å–µ—Ä–Ω—ã–π —Ç—Ä–µ–∫:",
                                                        ["Technical", "Management", "Consulting", "Research"],
                                                        key=f"track_{i}")
                            priority = st.selectbox("–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:",
                                                    ["High", "Medium", "Low"],
                                                    key=f"priority_{i}")

                        hr_notes = st.text_area("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ HR:",
                                                placeholder="–ó–∞–º–µ—Ç–∫–∏ HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞...",
                                                key=f"hr_notes_{i}")

                        col_approve, col_reject = st.columns(2)

                        with col_approve:
                            approve_btn = st.form_submit_button("‚úÖ –î–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö", type="primary")

                        with col_reject:
                            reject_btn = st.form_submit_button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å")

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π
                        if approve_btn:
                            try:
                                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è HR —Å–∏—Å—Ç–µ–º—ã
                                hr_profile_data = {
                                    'type': 'scanned_profile',
                                    'username': profile_info.get('user_name', 'Unknown'),
                                    'skills_detected': skills,
                                    'total_xp': user_profile.get('total_xp', 0),
                                    'level': user_profile.get('level', 1),
                                    'badges': user_profile.get('badges', []),
                                    'scan_data': {
                                        'profile_info': profile_info,
                                        'department': department,
                                        'salary_range': salary_range,
                                        'career_track': career_track,
                                        'priority': priority,
                                        'hr_notes': hr_notes,
                                        'manager_notes': data.get('manager_notes', ''),
                                        'processed_at': datetime.now().isoformat()
                                    }
                                }

                                # –î–æ–±–∞–≤–ª—è–µ–º –≤ HR —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ AI –æ–±—Ä–∞–±–æ—Ç–∫—É
                                result = hrsystem.add_document_to_database(hr_profile_data, resume_file['filename'])

                                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª –≤ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É
                                HR_FINAL_DIR.mkdir(exist_ok=True)
                                final_filepath = HR_FINAL_DIR / resume_file['filename']

                                data['workflow_stage'] = 'hr_approved'
                                data['hr_notes'] = hr_notes
                                data['hr_approved_by'] = "HR Specialist"
                                data['hr_approved_at'] = datetime.now().isoformat()

                                with open(final_filepath, 'w', encoding='utf-8') as f:
                                    json.dump(data, f, ensure_ascii=False, indent=2)

                                # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                                os.remove(resume_file['filepath'])

                                st.success(
                                    f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å {profile_info.get('user_name', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞')} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
                                st.success(result)
                                st.balloons()
                                time.sleep(2)
                                st.rerun()

                            except Exception as e:
                                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

                        elif reject_btn:
                            try:
                                # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é
                                data['workflow_stage'] = 'hr_rejected'
                                data['hr_notes'] = hr_notes
                                data['status'] = 'returned_to_manager'

                                rejected_filepath = MANAGER_REVIEW_DIR / "hr_rejected" / resume_file['filename']
                                rejected_filepath.parent.mkdir(exist_ok=True)

                                with open(rejected_filepath, 'w', encoding='utf-8') as f:
                                    json.dump(data, f, ensure_ascii=False, indent=2)

                                os.remove(resume_file['filepath'])

                                st.warning(f"‚ùå –ü—Ä–æ—Ñ–∏–ª—å {profile_info.get('user_name', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞')} –æ—Ç–∫–ª–æ–Ω–µ–Ω")
                                time.sleep(2)
                                st.rerun()

                            except Exception as e:
                                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ç–∞–±—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    with tab2:
        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö HR (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        st.header("üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö HR")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", len(employees))
        with col2:
            st.metric("–ü–æ–∑–∏—Ü–∏–∏", len(positions))
        with col3:
            st.metric("–ü—Ä–æ—Ñ–∏–ª–∏", len(profiles))
        with col4:
            total_xp = sum(profile.get('total_xp', 0) for profile in profiles)
            st.metric("–û–±—â–∏–π XP", total_xp)

        # –ü–æ–¥—Ç–∞–±—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        subtab1, subtab2, subtab3 = st.tabs(["üë• –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", "üíº –ü–æ–∑–∏—Ü–∏–∏", "üìã –ü—Ä–æ—Ñ–∏–ª–∏"])

        with subtab1:
            if employees:
                employees_df = pd.DataFrame(employees)
                st.dataframe(employees_df, use_container_width=True)
            else:
                st.info("üìÅ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö")

        with subtab2:
            if positions:
                positions_df = pd.DataFrame(positions)
                st.dataframe(positions_df, use_container_width=True)
            else:
                st.info("üìÅ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–∑–∏—Ü–∏—è—Ö")

        with subtab3:
            if profiles:
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π —Å –≥–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
                profiles_display = []
                for profile in profiles:
                    profiles_display.append({
                        '–ò–º—è': profile.get('username', ''),
                        '–£—Ä–æ–≤–µ–Ω—å': profile.get('level', 1),
                        'XP': profile.get('total_xp', 0),
                        '–ù–∞–≤—ã–∫–∏': len(profile.get('skills_detected', {})),
                        '–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è': len(profile.get('badges', [])),
                        '–û–±–Ω–æ–≤–ª–µ–Ω–æ': profile.get('updated_at', '')[:19] if profile.get('updated_at') else ''
                    })

                profiles_df = pd.DataFrame(profiles_display)
                st.dataframe(profiles_df, use_container_width=True)
            else:
                st.info("üìÅ –ù–µ—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π")

    with tab3:
        # AI –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç
        st.header("ü§ñ AI –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç")
        st.markdown("*RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å HR –¥–∞–Ω–Ω—ã–º–∏*")

        # –ü–æ–∏—Å–∫ —Å AI
        search_query = st.text_input("üí¨ –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å:",
                                   placeholder="–ù–∞–π–¥–∏—Ç–µ Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å –æ–ø—ã—Ç–æ–º > 3 –ª–µ—Ç")

        col1, col2 = st.columns([3, 1])

        with col1:
            search_type = st.radio("–¢–∏–ø –ø–æ–∏—Å–∫–∞:", ["RAG-–ø–æ–∏—Å–∫ —Å AI", "–û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫"], index=0)

        with col2:
            k_results = st.selectbox("–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:", [3, 5, 10, 15], index=1)

        if search_query and st.button("üîç –ù–∞–π—Ç–∏", type="primary"):
            with st.spinner("–ò—â–µ–º —á–µ—Ä–µ–∑ AI..."):
                if search_type == "RAG-–ø–æ–∏—Å–∫ —Å AI":
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
                    response = hrsystem.smart_query_with_context(search_query, k=k_results)
                    st.success("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AI –ø–æ–∏—Å–∫–∞:")
                    st.markdown("---")
                    st.write(response)
                else:
                    # –û–±—ã—á–Ω—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
                    search_results = hrsystem.hybrid_search(search_query, k=k_results)

                    if search_results:
                        st.success(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")

                        for i, result in enumerate(search_results, 1):
                            metadata = result['metadata']
                            with st.expander(f"{i}. {metadata['type'].title()} - Score: {result['score']:.3f}"):
                                st.write(result['text'])
                    else:
                        st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        # –ü–æ–∫–∞–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        with st.expander("üîç –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞", expanded=False):
            if search_query:
                search_results = hrsystem.hybrid_search(search_query, k=k_results)

                for i, result in enumerate(search_results, 1):
                    metadata = result['metadata']
                    st.write(f"**{i}. Score: {result['score']:.3f}**")
                    st.write(f"**–¢–∏–ø:** {metadata['type']}")

                    if metadata['type'] == 'employee':
                        emp_data = metadata['data']
                        st.write(f"**–ò–º—è:** {emp_data.get('name', '')}")
                    elif metadata['type'] == 'position':
                        pos_data = metadata['data']
                        st.write(f"**–ü–æ–∑–∏—Ü–∏—è:** {pos_data.get('title', '')}")

                    st.text(result['text'][:200] + "...")
                    st.markdown("---")

    with tab4:
        # –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º –∫–æ–¥–µ)
        st.header("üìÅ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        st.markdown("*–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ AI*")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        st.subheader("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        uploaded_files = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏:",
            type=['pdf', 'docx', 'xlsx', 'csv', 'txt', 'json'],
            accept_multiple_files=True,
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: PDF, DOCX, XLSX, CSV, TXT, JSON"
        )

        if uploaded_files and st.button("üì§ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã", type="primary"):
            results = []
            progress_bar = st.progress(0)

            for i, uploaded_file in enumerate(uploaded_files):
                with st.spinner(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {uploaded_file.name}..."):
                    # –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ AI
                    content, structured_data = hrsystem.parse_document(uploaded_file)

                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                    result = hrsystem.add_document_to_database(structured_data, uploaded_file.name)
                    results.append(f"{uploaded_file.name}: {result}")

                    progress_bar.progress((i + 1) / len(uploaded_files))

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            with st.sidebar:
                st.header("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                for result in results:
                    st.success(result)
                st.rerun()

        st.markdown("---")

        # –ò–º–ø–æ—Ä—Ç Smart Auto-Profiler –ø—Ä–æ—Ñ–∏–ª–µ–π
        st.subheader("ü§ñ –ò–º–ø–æ—Ä—Ç Smart Auto-Profiler –ø—Ä–æ—Ñ–∏–ª–µ–π")
        uploaded_profile = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç—å JSON –ø—Ä–æ—Ñ–∏–ª—å:",
            type=['json'],
            help="JSON —Ñ–∞–π–ª—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ Smart Auto-Profiler"
        )

        if uploaded_profile:
            try:
                profile_data = json.load(uploaded_profile)

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
                st.json(profile_data)

                if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å –≤ HR –±–∞–∑—É", type="primary"):
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è HR —Å–∏—Å—Ç–µ–º—ã
                    hr_profile_data = {
                        'type': 'scanned_profile',
                        'username': profile_data.get('username', 'Unknown'),
                        'skills_detected': profile_data.get('skills_detected', {}),
                        'total_xp': profile_data.get('total_xp', 0),
                        'level': profile_data.get('level', 1),
                        'badges': profile_data.get('badges', []),
                        'scan_data': profile_data
                    }

                    # –î–æ–±–∞–≤–ª—è–µ–º —á–µ—Ä–µ–∑ AI —Å–∏—Å—Ç–µ–º—É
                    result = hrsystem.add_document_to_database(hr_profile_data, uploaded_profile.name)
                    st.success(result)
                    st.rerun()

            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")

    with tab5:
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
        st.header("üìà HR –ê–Ω–∞–ª–∏—Ç–∏–∫–∞")

        if not employees and not positions and not profiles:
            st.info("üìä –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ —Ä–∞–∑–¥–µ–ª '–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö'")
            return

        # XP –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        if profiles:
            xp_data = [profile.get('total_xp', 0) for profile in profiles]
            if xp_data:
                xp_df = pd.DataFrame({
                    '–ò–º—è': [p.get('username', '') for p in profiles],
                    'XP': xp_data
                })
                st.bar_chart(xp_df.set_index('–ò–º—è'))
        else:
            st.info("üìä –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ XP")


def render_manager_interface():
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è"""
    st.markdown("## üëî –ü–∞–Ω–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è")
    st.markdown("*–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—é–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤*")

    # –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫—É —Å —Ä–µ–∑—é–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
    resume_files = []
    if JOB_RESUME_DIR.exists():
        for file_path in JOB_RESUME_DIR.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                if data.get('status') == 'ready_for_manager_review':
                    resume_files.append({
                        'filename': file_path.name,
                        'filepath': str(file_path),
                        'data': data,
                        'modified': datetime.fromtimestamp(file_path.stat().st_mtime)
                    })
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")

    if not resume_files:
        st.info("üìÅ –ù–µ—Ç —Ä–µ–∑—é–º–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º")
        st.markdown("*–†–µ–∑—é–º–µ –ø–æ—è–≤—è—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏*")
        return

    st.success(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(resume_files)} —Ä–µ–∑—é–º–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Ä–µ–∑—é–º–µ
    for i, resume_file in enumerate(resume_files):
        data = resume_file['data']
        profile_info = data.get('profile_info', {})
        skills = data.get('skills', {})
        user_profile = data.get('user_profile', {})

        with st.expander(f"üìÑ {profile_info.get('user_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} - {resume_file['filename']}",
                         expanded=i < 2):
            col1, col2 = st.columns([2, 1])

            with col1:
                st.markdown("### üë§ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ")
                st.write(f"**–ò–º—è:** {profile_info.get('user_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.write(f"**–ñ–µ–ª–∞–µ–º–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å:** {profile_info.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.write(f"**Email:** {profile_info.get('email', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.write(f"**–¢–µ–ª–µ—Ñ–æ–Ω:** {profile_info.get('phone', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.write(f"**–õ–æ–∫–∞—Ü–∏—è:** {profile_info.get('location', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")

                if profile_info.get('summary'):
                    st.markdown("**–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:**")
                    st.write(profile_info['summary'])

                if profile_info.get('career_goals'):
                    st.markdown("**–ö–∞—Ä—å–µ—Ä–Ω—ã–µ —Ü–µ–ª–∏:**")
                    st.write(profile_info['career_goals'])

                # –ù–∞–≤—ã–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º - –∑–∞–º–µ–Ω—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ expander'—ã –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                st.markdown("### üíº –ù–∞–≤—ã–∫–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞")

                skills_by_category = defaultdict(list)
                for skill_name, skill_data in skills.items():
                    skills_by_category[skill_data.get('category', '–ü—Ä–æ—á–µ–µ')].append((skill_name, skill_data))

                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞–≤—ã–∫–æ–≤
                if skills_by_category:
                    categories = list(skills_by_category.keys())
                    if len(categories) > 1:
                        skill_tabs = st.tabs([f"üìÇ {category}" for category in categories])

                        for idx, (category, category_skills) in enumerate(skills_by_category.items()):
                            with skill_tabs[idx]:
                                st.markdown(f"**{len(category_skills)} –Ω–∞–≤—ã–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏**")

                                for skill_name, skill_data in category_skills:
                                    icon = skill_data.get('icon', 'üîß')
                                    level = skill_data.get('experience_level', '–ù–∞—á–∏–Ω–∞—é—â–∏–π')
                                    confidence = skill_data.get('confidence', 0)

                                    # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–≤—ã–∫–∞
                                    with st.container():
                                        st.markdown(f"**{icon} {skill_name}** ({level}) - Confidence: {confidence:.2f}")

                                        if skill_data.get('description'):
                                            st.caption(f"–û–ø–∏—Å–∞–Ω–∏–µ: {skill_data['description']}")

                                        st.caption(
                                            f"–ò—Å—Ç–æ—á–Ω–∏–∫: {skill_data.get('evidence_type', 'unknown')} | –ß–∞—Å—Ç–æ—Ç–∞: {skill_data.get('frequency', 0)}")
                                        st.markdown("---")
                    else:
                        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –±–µ–∑ —Ç–∞–±–æ–≤
                        category, category_skills = list(skills_by_category.items())[0]
                        st.markdown(f"#### üìÇ {category} ({len(category_skills)} –Ω–∞–≤—ã–∫–æ–≤)")

                        for skill_name, skill_data in category_skills:
                            icon = skill_data.get('icon', 'üîß')
                            level = skill_data.get('experience_level', '–ù–∞—á–∏–Ω–∞—é—â–∏–π')
                            confidence = skill_data.get('confidence', 0)

                            with st.container():
                                st.markdown(f"**{icon} {skill_name}** ({level}) - Confidence: {confidence:.2f}")

                                if skill_data.get('description'):
                                    st.caption(f"–û–ø–∏—Å–∞–Ω–∏–µ: {skill_data['description']}")

                                st.caption(
                                    f"–ò—Å—Ç–æ—á–Ω–∏–∫: {skill_data.get('evidence_type', 'unknown')} | –ß–∞—Å—Ç–æ—Ç–∞: {skill_data.get('frequency', 0)}")
                                st.markdown("---")
                else:
                    st.info("–ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

            with col2:
                # –ì–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏—è
                st.markdown("### üéÆ –ò–≥—Ä–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å")
                st.metric("–£—Ä–æ–≤–µ–Ω—å", user_profile.get('level', 1))
                st.metric("–û–±—â–∏–π XP", user_profile.get('total_xp', 0))
                st.metric("Streak", user_profile.get('daily_streak', 0))

                badges = user_profile.get('badges', [])
                if badges:
                    st.write("**üèÜ –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**")
                    for badge in badges[:5]:
                        st.write(f"‚Ä¢ {badge}")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≤—ã–∫–æ–≤
                st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                st.write(f"**–í—Å–µ–≥–æ –Ω–∞–≤—ã–∫–æ–≤:** {len(skills)}")

                categories = {}
                for skill_data in skills.values():
                    cat = skill_data.get('category', '–ü—Ä–æ—á–µ–µ')
                    categories[cat] = categories.get(cat, 0) + 1

                for cat, count in categories.items():
                    st.write(f"‚Ä¢ {cat}: {count}")

            # –§–æ—Ä–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º
            st.markdown("---")
            st.markdown("### üëî –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º")

            form_key = f"manager_form_{i}"
            with st.form(form_key):
                manager_notes = st.text_area(
                    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è:",
                    placeholder="–í–∞—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ –ø—Ä–æ—Ñ–∏–ª—é —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞...",
                    key=f"notes_{i}"
                )

                col_approve, col_reject = st.columns(2)

                with col_approve:
                    approve_btn = st.form_submit_button("‚úÖ –û–¥–æ–±—Ä–∏—Ç—å –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ HR", type="primary")

                with col_reject:
                    reject_btn = st.form_submit_button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫—É")

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π
                if approve_btn:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                        (MANAGER_REVIEW_DIR / "approved").mkdir(parents=True, exist_ok=True)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª—è
                        data['workflow_stage'] = 'manager_approved'
                        data['manager_notes'] = manager_notes
                        data['manager_approved_by'] = "Manager"  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
                        data['manager_approved_at'] = datetime.now().isoformat()

                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É manager_review
                        new_filepath = MANAGER_REVIEW_DIR / "approved" / resume_file['filename']

                        with open(new_filepath, 'w', encoding='utf-8') as f:
                            json.dump(data, f, ensure_ascii=False, indent=2)

                        # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                        os.remove(resume_file['filepath'])

                        st.success(
                            f"‚úÖ –†–µ–∑—é–º–µ {profile_info.get('user_name', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞')} –æ–¥–æ–±—Ä–µ–Ω–æ –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ HR!")
                        st.balloons()
                        time.sleep(2)
                        st.rerun()

                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

                elif reject_btn:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                        (MANAGER_REVIEW_DIR / "rejected").mkdir(parents=True, exist_ok=True)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                        data['workflow_stage'] = 'manager_rejected'
                        data['manager_notes'] = manager_notes
                        data['status'] = 'returned_to_employee'

                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –ø–∞–ø–∫—É –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö
                        rejected_filepath = MANAGER_REVIEW_DIR / "rejected" / resume_file['filename']

                        with open(rejected_filepath, 'w', encoding='utf-8') as f:
                            json.dump(data, f, ensure_ascii=False, indent=2)

                        # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                        os.remove(resume_file['filepath'])

                        st.warning(f"‚ùå –†–µ–∑—é–º–µ {profile_info.get('user_name', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞')} –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ")
                        time.sleep(2)
                        st.rerun()

                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")


def render_employee_interface(user_settings):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ —Å Smart Auto-Profiler"""

    render_header()

    profiler = SmartAutoProfiler()

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if not st.session_state.user_profile and user_settings["username"]:
        st.session_state.user_profile = UserProfile(
            username=user_settings["username"],
            session_start=datetime.now(),
            skills_detected={}
        )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–¥–µ—Ç –ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤
    if render_skills_editor():
        return

    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞
    st.markdown("### üîç Smart Auto-Profiler")
    st.markdown("*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è*")

    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ", type="primary", use_container_width=True):
            with st.spinner("–°–∫–∞–Ω–∏—Ä—É–µ–º –≤–∞—à–∏ –Ω–∞–≤—ã–∫–∏..."):
                all_detected_skills = []

                # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
                process_skills = profiler.scan_active_processes()
                all_detected_skills.extend(process_skills)
                st.success(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(process_skills)} –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")

                # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–æ–≤
                if user_settings["venv_path"]:
                    package_skills = profiler.scan_installed_packages(user_settings["venv_path"])
                    all_detected_skills.extend(package_skills)
                    st.success(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(package_skills)} –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤")

                # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤
                if user_settings["project_paths"]:
                    file_skills = profiler.scan_project_files(user_settings["project_paths"])
                    all_detected_skills.extend(file_skills)
                    st.success(f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(file_skills)} –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤")

                if all_detected_skills:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∞–≤—ã–∫–∏
                    skills_dict = {}
                    for skill in all_detected_skills:
                        if skill.skill_name not in skills_dict:
                            skills_dict[skill.skill_name] = skill
                        else:
                            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ (–±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
                            existing = skills_dict[skill.skill_name]
                            if skill.confidence > existing.confidence:
                                skills_dict[skill.skill_name] = skill

                    st.session_state.scanned_skills = skills_dict

                    # –û–±–Ω–æ–≤–ª—è–µ–º XP –ø—Ä–æ—Ñ–∏–ª—è
                    if st.session_state.user_profile:
                        xp_gained, new_skills = profiler.update_profile_xp(list(skills_dict.values()))
                        if xp_gained > 0:
                            st.success(f"üéâ –ü–æ–ª—É—á–µ–Ω–æ {xp_gained} XP! –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(new_skills)} –Ω–æ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤!")

                    st.balloons()
                else:
                    st.warning("üòî –ù–∞–≤—ã–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π.")

    # –ü–æ–∫–∞–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    if st.session_state.scanned_skills:
        st.markdown("---")
        st.markdown("### üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –Ω–∞–≤—ã–∫–∏")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        skills = st.session_state.scanned_skills
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("–í—Å–µ–≥–æ –Ω–∞–≤—ã–∫–æ–≤", len(skills))
        with col2:
            categories = len(set(skill.category for skill in skills.values()))
            st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", categories)
        with col3:
            avg_confidence = sum(skill.confidence for skill in skills.values()) / len(skills)
            st.metric("–°—Ä. —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{avg_confidence:.2f}")
        with col4:
            high_conf_skills = sum(1 for skill in skills.values() if skill.confidence > 0.8)
            st.metric("–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä.", high_conf_skills)

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        skills_by_category = defaultdict(list)
        for skill_name, skill in skills.items():
            skills_by_category[skill.category].append((skill_name, skill))

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        if skills_by_category:
            categories = list(skills_by_category.keys())
            tabs = st.tabs([f"{categories[i]}" for i in range(len(categories))])

            for i, category in enumerate(categories):
                with tabs[i]:
                    st.markdown(f"### üìÇ {category}")
                    category_skills = skills_by_category[category]

                    for skill_name, skill in sorted(category_skills, key=lambda x: x[1].confidence, reverse=True):
                        col1, col2, col3 = st.columns([2, 1, 1])

                        with col1:
                            st.markdown(f"**{getattr(skill, 'icon', 'üîß')} {skill.skill_name}**")
                            if skill.description:
                                st.caption(skill.description)

                        with col2:
                            st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{skill.confidence:.2f}")
                            st.caption(f"–£—Ä–æ–≤–µ–Ω—å: {skill.experience_level}")

                        with col3:
                            st.metric("–ò—Å—Ç–æ—á–Ω–∏–∫", skill.evidence_type.title())
                            if skill.frequency > 0:
                                st.caption(f"–ß–∞—Å—Ç–æ—Ç–∞: {skill.frequency}")
                            elif skill.total_time_minutes > 0:
                                st.caption(f"–í—Ä–µ–º—è: {skill.total_time_minutes}–º")

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        st.markdown("---")
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–≤—ã–∫–∏"):
                st.session_state.skills_edit_mode = True
                st.rerun()

        with col2:
            if st.button("üìÑ –°–æ–∑–¥–∞—Ç—å —Ä–µ–∑—é–º–µ-–ø—Ä–æ—Ñ–∏–ª—å"):
                st.session_state.show_profile_creation = True
                st.rerun()

        with col3:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å"):
                st.session_state.scanned_skills = {}
                st.session_state.user_profile = None
                st.rerun()

    # –ì–µ–π–º–∏—Ñ–∏–∫–∞—Ü–∏—è
    if st.session_state.user_profile:
        render_gamification_dashboard()

        # –ò—Å—Ç–æ—Ä–∏—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–π
        if st.session_state.scan_history:
            with st.expander("üìà –ò—Å—Ç–æ—Ä–∏—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–π"):
                history_df = pd.DataFrame(st.session_state.scan_history)
                st.dataframe(history_df)

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è-—Ä–µ–∑—é–º–µ
    if st.session_state.get('show_profile_creation', False):
        render_profile_creation_interface()


def render_profile_creation_interface():
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è-—Ä–µ–∑—é–º–µ"""
    st.markdown("---")
    st.markdown("### üìù –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è-—Ä–µ–∑—é–º–µ")
    st.markdown("*–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è*")

    with st.form("profile_creation_form"):
        col1, col2 = st.columns(2)

        with col1:
            user_name = st.text_input("üë§ –ü–æ–ª–Ω–æ–µ –∏–º—è:",
                                      value=st.session_state.user_profile.username if st.session_state.user_profile else "")
            email = st.text_input("üìß Email:")
            phone = st.text_input("üì± –¢–µ–ª–µ—Ñ–æ–Ω:")
            location = st.text_input("üåç –õ–æ–∫–∞—Ü–∏—è:", value="–ú–æ—Å–∫–≤–∞")

        with col2:
            position = st.text_input("üíº –ñ–µ–ª–∞–µ–º–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å:")
            department = st.text_input("üè¢ –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç–¥–µ–ª:")
            linkedin = st.text_input("üîó LinkedIn –ø—Ä–æ—Ñ–∏–ª—å:")
            github = st.text_input("üíª GitHub –ø—Ä–æ—Ñ–∏–ª—å:")

        summary = st.text_area("üìã –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (summary):",
                               placeholder="–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞—à–∏—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ –∏ –æ–ø—ã—Ç–∞...")

        career_goals = st.text_area("üéØ –ö–∞—Ä—å–µ—Ä–Ω—ã–µ —Ü–µ–ª–∏:",
                                    placeholder="–í–∞—à–∏ –∫–∞—Ä—å–µ—Ä–Ω—ã–µ —Ü–µ–ª–∏ –∏ –ø–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è...")

        additional_skills = st.text_area("‚ûï –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏:",
                                         placeholder="–ù–∞–≤—ã–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã...")

        col_submit, col_cancel = st.columns(2)

        with col_submit:
            submit_btn = st.form_submit_button("üöÄ –°–æ–∑–¥–∞—Ç—å –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å", type="primary")

        with col_cancel:
            cancel_btn = st.form_submit_button("‚ùå –û—Ç–º–µ–Ω–∞")

        if submit_btn:
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª—è
                profile_data = {
                    "user_name": user_name,
                    "email": email,
                    "phone": phone,
                    "location": location,
                    "position": position,
                    "department": department,
                    "linkedin": linkedin,
                    "github": github,
                    "summary": summary,
                    "career_goals": career_goals,
                    "additional_skills": additional_skills,
                    "created_at": datetime.now().isoformat()
                }

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞–≤—ã–∫–∏
                skills_data = st.session_state.scanned_skills

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
                if additional_skills:
                    additional_skills_list = [s.strip() for s in additional_skills.split(',') if s.strip()]
                    for skill_name in additional_skills_list:
                        if skill_name not in skills_data:
                            skills_data[skill_name] = SkillDetection(
                                skill_name=skill_name,
                                evidence_type="manual",
                                confidence=0.8,
                                last_detected=datetime.now(),
                                category="Manual",
                                experience_level="–°—Ä–µ–¥–Ω–∏–π",
                                description="–î–æ–±–∞–≤–ª–µ–Ω–æ –≤—Ä—É—á–Ω—É—é"
                            )

                # –°–æ–∑–¥–∞–µ–º Smart Auto-Profiler –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                profiler = SmartAutoProfiler()
                file_path = profiler.save_profile_to_resume_folder(profile_data, skills_data)

                st.success("üéâ –ü—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é!")
                st.info(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")
                st.balloons()

                # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è
                st.session_state.show_profile_creation = False
                time.sleep(2)
                st.rerun()

            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {e}")

        if cancel_btn:
            st.session_state.show_profile_creation = False
            st.rerun()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    # –†–µ–Ω–¥–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ —Ä–æ–ª–µ–π
    render_header()

    # –ü–æ–ª—É—á–∞–µ–º —Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_role = render_role_selector()

    # –†–µ–Ω–¥–µ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–æ–ª–∏
    if user_role == "employee":
        user_settings = render_sidebar()
        render_employee_interface(user_settings)
    elif user_role == "manager":
        render_manager_interface()
    elif user_role == "hr":
        render_hr_interface()


if __name__ == "__main__":
    main()
